{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5aeda95-3583-446a-aee3-3c143595869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ OUT_univariate_classifier       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mCustomLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m160\u001b[0m)        │       \u001b[38;5;34m103,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m160\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mCustomLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m147,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mCustomLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │        \u001b[38;5;34m66,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │        \u001b[38;5;34m38,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m2,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m2,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ OUT_univariate_classifier       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m147\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">362,605</span> (1.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m362,605\u001b[0m (1.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">362,603</span> (1.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m362,603\u001b[0m (1.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "class CustomLSTM(LSTM):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs.pop('time_major', None)  # Remove the 'time_major' argument if it exists\n",
    "        super(CustomLSTM, self).__init__(*args, **kwargs)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'CustomLSTM': CustomLSTM})\n",
    "\n",
    "trained_model = load_model(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\4G-Models\\Models\\univariate_classifier.hdf5\", custom_objects={'LSTM': CustomLSTM})\n",
    "\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b2448c-a3bd-4651-b5ca-1b9811c27a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4g\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "X_train = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Training\\univariate_classifier_train_x.npy\")  # Shape should be (num_samples, time_steps, num_features)\n",
    "y_train = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Training\\univariate_classifier_train_y.npy\")  # Shape should be (num_samples, num_classes)\n",
    "X_test = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Testing\\univariate_classifier_test_x.npy\")\n",
    "y_test = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Testing\\univariate_classifier_test_y.npy\")\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5f1586-b398-4fc7-a0a2-c0ad7eda1d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\pranali\\AppData\\Local\\Temp\\tmprzo1df1k\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\pranali\\AppData\\Local\\Temp\\tmprzo1df1k\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\pranali\\AppData\\Local\\Temp\\tmprzo1df1k'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10, 1), dtype=tf.float32, name='lstm_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2451805175440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451773795280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451805172368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451805175248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806423952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806424144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806422416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806426064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806425104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806427792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806428368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806428560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806429328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806429712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806430864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806431056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2451806431824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "\n",
    "#quantized model default\n",
    "\n",
    "# Convert the model to a TensorFlow Lite model with post-training quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(trained_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Enable Select TF ops to support operations not natively supported by TFLite\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, \n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "# Disable lowering of tensor list operations, which might be causing the error\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# Enable resource variable support\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "# Convert the model\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c82a20-9a1d-4d3e-b8dc-d2cdc5dd703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TFLite model\n",
    "with open('4g_classifier_dynamic.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b2693f-ec54-461c-bc72-25b67abf5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path='4g_classifier_dynamic.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get details of input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5df47bd-420e-45ec-9963-1bec3b0b99e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Inference Time for quantized classifier 4g sample: 63.802561 seconds\n",
      "Avg Inference Time for quantized classifier 4g sample: 0.002395 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize list to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "for i in range(X_test.shape[0]):\n",
    "    # Prepare the input data (trim the extra dimension if necessary)\n",
    "    input_data = X_test[i]  # Trim to match the expected shape (1, 10, 10)\n",
    "    input_data = np.expand_dims(input_data, axis=0).astype(np.float32)\n",
    "    \n",
    "    # Set the input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get the output tensor\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Append prediction to the list\n",
    "    predictions.append(output_data)\n",
    "\n",
    "end_time = time.time()\n",
    "total_inference_time = end_time - start_time\n",
    "avg_inference_time = total_inference_time / len(X_test)\n",
    "\n",
    "print(f\"Total Inference Time for quantized classifier 4g sample: {total_inference_time:.6f} seconds\")\n",
    "print(f\"Avg Inference Time for quantized classifier 4g sample: {avg_inference_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f477dee5-ef28-468b-abc8-680f59afe3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized TFLite model size: 416.44 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get the size of the saved quantized TFLite model\n",
    "model_size = os.path.getsize('4g_classifier_dynamic.tflite')\n",
    "print(f\"Quantized TFLite model size: {model_size / 1024:.2f} KB\")  # Convert to KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10edefd4-6c8e-4f2b-9125-9614feca529c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  561     0  3434]\n",
      " [  101     0  7890]\n",
      " [   67     0 14590]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.77      0.14      0.24      3995\n",
      "  Medium (1)       0.00      0.00      0.00      7991\n",
      "    High (2)       0.56      1.00      0.72     14657\n",
      "\n",
      "    accuracy                           0.57     26643\n",
      "   macro avg       0.44      0.38      0.32     26643\n",
      "weighted avg       0.43      0.57      0.43     26643\n",
      "\n",
      "Accuracy: 0.5686671921330181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to run inference using the interpreter\n",
    "def run_inference(interpreter, X_test):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        # Preprocess the input as per your model's input requirements\n",
    "        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)  # Adjust datatype if needed\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        predictions.append(output_data)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Assume X_test and y_test are your test data and labels\n",
    "# Run inference on the quantized model\n",
    "predictions = run_inference(interpreter, X_test)\n",
    "\n",
    "# Convert predictions to the correct shape if needed (e.g., flattening)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# For classification, get the predicted class and the true class\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print the classification report\n",
    "target_names = [\"Low (0)\", \"Medium (1)\", \"High (2)\"]\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=target_names)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: If you need to compute accuracy again\n",
    "accuracy = np.sum(predicted_classes == true_classes) / len(true_classes)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3393fdd9-0c52-470a-871b-4ca741871a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  561     0  3434]\n",
      " [  101     0  7890]\n",
      " [   67     0 14590]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.77      0.14      0.24      3995\n",
      "  Medium (1)       0.00      0.00      0.00      7991\n",
      "    High (2)       0.56      1.00      0.72     14657\n",
      "\n",
      "    accuracy                           0.57     26643\n",
      "   macro avg       0.44      0.38      0.32     26643\n",
      "weighted avg       0.43      0.57      0.43     26643\n",
      "\n",
      "Accuracy: 0.5686671921330181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.28719025782544955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Function to run inference using the interpreter\n",
    "def run_inference(interpreter, X_test):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        # Preprocess the input as per your model's input requirements\n",
    "        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)  # Adjust datatype if needed\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        predictions.append(output_data)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Assume X_test and y_test are your test data and labels\n",
    "# Run inference on the quantized model\n",
    "predictions = run_inference(interpreter, X_test)\n",
    "\n",
    "# Convert predictions to the correct shape if needed (e.g., flattening)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# For classification, get the predicted class and the true class\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print the classification report\n",
    "target_names = [\"Low (0)\", \"Medium (1)\", \"High (2)\"]\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=target_names)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: If you need to compute accuracy again\n",
    "accuracy = np.sum(predicted_classes == true_classes) / len(true_classes)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Run inference on the quantized model\n",
    "predictions = run_inference(interpreter, X_test)\n",
    "\n",
    "# Convert predictions to the correct shape if needed (e.g., flattening)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Compute loss (assuming Mean Squared Error for regression, adjust for classification)\n",
    "mse = np.mean(np.square(predictions - y_test))\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7a13b-6bba-4514-9ab9-da342879de94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
