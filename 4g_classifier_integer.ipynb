{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff38f544-ff3f-4a05-9ac2-56db45de7de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomLSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ OUT_univariate_classifier       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mCustomLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m160\u001b[0m)        │       \u001b[38;5;34m103,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m160\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mCustomLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m147,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mCustomLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │        \u001b[38;5;34m66,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │        \u001b[38;5;34m38,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m2,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │         \u001b[38;5;34m2,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ OUT_univariate_classifier       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m147\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">362,605</span> (1.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m362,605\u001b[0m (1.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">362,603</span> (1.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m362,603\u001b[0m (1.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "class CustomLSTM(LSTM):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        kwargs.pop('time_major', None)  # Remove the 'time_major' argument if it exists\n",
    "        super(CustomLSTM, self).__init__(*args, **kwargs)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'CustomLSTM': CustomLSTM})\n",
    "\n",
    "trained_model = load_model(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\4G-Models\\Models\\univariate_classifier.hdf5\", custom_objects={'LSTM': CustomLSTM})\n",
    "\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89eabc78-794f-4b77-9bbf-ca76e514aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4g\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "X_train = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Training\\univariate_classifier_train_x.npy\")  # Shape should be (num_samples, time_steps, num_features)\n",
    "y_train = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Training\\univariate_classifier_train_y.npy\")  # Shape should be (num_samples, num_classes)\n",
    "X_test = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Testing\\univariate_classifier_test_x.npy\")\n",
    "y_test = np.load(r\"C:\\Users\\pranali\\Desktop\\Throughput_prediction\\test_train_vis\\Testing\\univariate_classifier_test_y.npy\")\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e9335c-86cd-4729-937b-056a7ff4b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\pranali\\AppData\\Local\\Temp\\tmp20ip7a3e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\pranali\\AppData\\Local\\Temp\\tmp20ip7a3e\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\pranali\\AppData\\Local\\Temp\\tmp20ip7a3e'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10, 1), dtype=tf.float32, name='lstm_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2005842919056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005811538896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005842915984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005842918864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844167568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844167760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844166032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844169680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844168720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844171408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844171984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844172176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844172944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844173328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844174480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844174672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2005844175440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#integer quantization\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define the representative dataset generator for quantization calibration\n",
    "def representative_data_gen():\n",
    "    for input_value in X_train[:100]:  # Use a small sample of your training data\n",
    "        input_value = np.expand_dims(input_value, axis=0).astype(np.float32)\n",
    "        yield [input_value]\n",
    "\n",
    "# Convert the model to TensorFlow Lite with full integer quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(trained_model)\n",
    "\n",
    "# Set optimization to full integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Provide representative dataset for integer quantization\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Set the supported operations to enable both built-in ops and Select TF ops\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, \n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "# Set the input and output tensors to be int8 for full integer quantization\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8 based on your need\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8 based on your need\n",
    "\n",
    "# Disable lowering of tensor list operations to avoid related issues\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# Enable resource variable support (required for LSTM layers)\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "# Convert the model\n",
    "tflite_quant_model = converter.convert()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3848f389-a95b-4561-8a29-e923e0e1fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TFLite model\n",
    "with open('4g_classifier_integer.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe8b7bd-f8e1-4e16-8b43-5f77637759eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path='4g_classifier_integer.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get details of input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858d0acc-1c28-4d31-b7b6-a169026e84ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time for full integer quantized model: 94.662094 seconds\n",
      "Avg Inference Time for full integer quantized model: 0.003553 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function to quantize input data\n",
    "def quantize_input(input_data, input_scale, input_zero_point):\n",
    "    return np.round(input_data / input_scale + input_zero_point).astype(np.int8)\n",
    "\n",
    "# Initialize list to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Get the quantization parameters for the input tensor\n",
    "input_scale = input_details[0]['quantization'][0]\n",
    "input_zero_point = input_details[0]['quantization'][1]\n",
    "\n",
    "# Iterate over each sample in X_test\n",
    "start_time = time.time()\n",
    "for i in range(X_test.shape[0]):\n",
    "    # Prepare the input data\n",
    "    input_data = X_test[i].astype(np.float32)  # Keep as float32 for quantization\n",
    "    input_data = quantize_input(input_data, input_scale, input_zero_point)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    \n",
    "    # Set the input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get the output tensor\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions.append(output_data)\n",
    "\n",
    "end_time = time.time()\n",
    "inference_time = (end_time - start_time)\n",
    "print(f\"Inference Time for full integer quantized model: {inference_time:.6f} seconds\")\n",
    "\n",
    "avg_inference_time = inference_time / len(X_test)\n",
    "print(f\"Avg Inference Time for full integer quantized model: {avg_inference_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a5d0568-d21a-4958-ad71-a5e81c18a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized TFLite model size: 429.24 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the size of the saved quantized TFLite model\n",
    "model_size = os.path.getsize('4g_classifier_integer.tflite')\n",
    "print(f\"Quantized TFLite model size: {model_size / 1024:.2f} KB\")  # Convert to KB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b7c8284-abf2-4dd3-9e87-2f7143f5ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5504\n",
      "Loss: 113.2616\n",
      "\n",
      "Confusion Matrix:\n",
      "[[    0   372  3623]\n",
      " [    0    19  7972]\n",
      " [    0    13 14644]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Low (0)       0.00      0.00      0.00      3995\n",
      "  Medium (1)       0.05      0.00      0.00      7991\n",
      "    High (2)       0.56      1.00      0.72     14657\n",
      "\n",
      "    accuracy                           0.55     26643\n",
      "   macro avg       0.20      0.33      0.24     26643\n",
      "weighted avg       0.32      0.55      0.40     26643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pranali\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Function to quantize input data\n",
    "def quantize_input(input_data, input_scale, input_zero_point):\n",
    "    return np.round(input_data / input_scale + input_zero_point).astype(np.int8)\n",
    "\n",
    "# Load the quantized TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get the quantization parameters for the input tensor\n",
    "input_scale = input_details[0]['quantization'][0]\n",
    "input_zero_point = input_details[0]['quantization'][1]\n",
    "\n",
    "# Initialize list to store predictions and logits for loss calculation\n",
    "predictions = []\n",
    "logits = []\n",
    "\n",
    "# Iterate over each sample in X_test\n",
    "for i in range(X_test.shape[0]):\n",
    "    # Prepare the input data\n",
    "    input_data = X_test[i].astype(np.float32)  # Keep as float32 for quantization\n",
    "    input_data = quantize_input(input_data, input_scale, input_zero_point)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    \n",
    "    # Set the input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get the output tensor (classification result)\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # Cast the logits to float32 for loss calculation\n",
    "    logits.append(output_data.astype(np.float32))  # Cast to float32\n",
    "    predictions.append(np.argmax(output_data, axis=1))  # Store predicted class\n",
    "\n",
    "# Convert predictions and logits to numpy arrays and squeeze the shape if necessary\n",
    "predictions = np.squeeze(np.array(predictions))\n",
    "logits = np.squeeze(np.array(logits))\n",
    "\n",
    "# For classification, get the predicted class and the true class\n",
    "true_classes = np.argmax(y_test, axis=1)  # Assuming y_test is one-hot encoded\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = np.sum(predictions == true_classes) / len(true_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate the loss using logits (after casting them to float32)\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy(true_classes, logits, from_logits=True)\n",
    "print(f\"Loss: {np.mean(loss):.4f}\")\n",
    "\n",
    "# Calculate and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predictions)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "target_names = [\"Low (0)\", \"Medium (1)\", \"High (2)\"]\n",
    "class_report = classification_report(true_classes, predictions, target_names=target_names)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90cc9e6-e102-47c9-9399-5f09dd28dfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
